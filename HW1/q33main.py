# -*- coding: utf-8 -*-
"""SpamDetection3.3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UPYjPYWt7QGncovRKpXfQzWIiNUdU4uT
"""

import pandas as pd
import numpy as np
from time import perf_counter
from google.colab import drive
drive.mount('/content/drive')

!cd /mnt/c/Users/pc/OneDrive/Masaüstü/

features = pd.read_csv("/content/drive/MyDrive/hw1_datasets/q3/sms_train_features.csv", index_col=0)
labels = pd.read_csv("/content/drive/MyDrive/hw1_datasets/q3/sms_train_labels.csv", index_col=0)
feature_array = features.to_numpy()
label_array = labels.to_numpy().reshape(1, -1)[0]

ignored_indices = np.nonzero(np.sum(feature_array, axis = 0) == 0)[0]
comp_feature_array = np.delete(feature_array, ignored_indices, 1)

prob_spam = sum(label_array)/len(label_array)
prob_ham = 1 - prob_spam
n_data = len(features)
n_vocab = features.size // n_data

spam_data = comp_feature_array[label_array == 1]
ham_data = comp_feature_array[label_array == 0]
n_spam = len(spam_data)
n_ham = len(ham_data)

prb_spam_array = np.zeros(n_vocab)
prb_ham_array = np.zeros(n_vocab)

n_words_in_spam = np.sum(spam_data)
n_words_in_ham = np.sum(ham_data)
comp_n_vocab = n_vocab - len(ignored_indices)

MI = np.zeros(comp_n_vocab)
for i in range(comp_n_vocab):
    N_xx = np.zeros((2, 2))
    for j in range(n_data):
        N_xx[int(bool(comp_feature_array[j, i])), label_array[j]] += 1
    mutual_temp = 0
    if N_xx[1,1] != 0:
        mutual_temp += (N_xx[1,1] / n_data) * np.log2((n_data*N_xx[1,1]) / ((N_xx[1,0]+N_xx[1,1]) * (N_xx[0,1] + N_xx[1,1])))
    if N_xx[0,1] != 0:
        mutual_temp += (N_xx[0,1] / n_data) * np.log2((n_data*N_xx[0,1]) / ((N_xx[0,1]+N_xx[0,0]) * (N_xx[0,1] + N_xx[1,1])))
    if N_xx[1,0] != 0:
        mutual_temp += (N_xx[1,0] / n_data) * np.log2((n_data*N_xx[1,0]) / ((N_xx[1,0]+N_xx[1,1]) * (N_xx[1,0] + N_xx[0,0])))
    if N_xx[0,0] != 0:
        mutual_temp += (N_xx[0,0] / n_data) * np.log2((n_data*N_xx[0,0]) / ((N_xx[0,0]+N_xx[0,1]) * (N_xx[1,0] + N_xx[0,0])))

    MI[i] = mutual_temp
MI = (-MI).argsort()

N = 600
MI = MI[:N]
comp_feature_array = comp_feature_array[:, MI]

def write_all():
    spam_word_probs = sum(spam_data) / n_words_in_spam
    ham_word_probs = sum(ham_data) / n_words_in_ham
    spam_word_probs = spam_word_probs[MI]
    ham_word_probs = ham_word_probs[MI]

    def predict(test_data):
        if type(test_data) != np.ndarray:
            test_data = np.array(test_data)
        test_data = np.delete(test_data, ignored_indices)
        test_data = test_data[MI]
        predict_spam = np.log10(prob_spam)
        predict_ham = np.log10(prob_ham)
        for i in range(N):
            ti = int(test_data[i] != 0)
            P_xj_spam = spam_word_probs[i]
            P_xj_ham = ham_word_probs[i]
            predict_spam += np.log10(ti * P_xj_spam + (1-ti) * (1-P_xj_spam))
            predict_ham += np.log10(ti * P_xj_ham + (1-ti) * (1-P_xj_ham))
        return int(predict_spam > predict_ham)

    true_pos = 0
    true_neg = 0
    false_pos = 0
    false_neg = 0
    t1 = perf_counter()
    for i in range(n_data):
        prediction = predict(feature_array[i])
        if prediction == label_array[i]:
            if prediction == 1:
                true_pos += 1
            else:
                true_neg += 1
        else:
            if prediction == 1:
                false_pos += 1
            else:
                false_neg += 1
    t2 = perf_counter()
    time_tr = t2 - t1
    acc_tr = 100 * (true_neg + true_pos) / n_data
    test_features = pd.read_csv("/content/drive/MyDrive/hw1_datasets/q3/sms_test_features.csv", index_col=0)
    test_labels = pd.read_csv("/content/drive/MyDrive/hw1_datasets/q3/sms_test_labels.csv", index_col=0)
    test_feature_array = test_features.to_numpy()
    test_label_array = test_labels.to_numpy().reshape(1, -1)[0]

    true_pos = 0
    true_neg = 0
    false_pos = 0
    false_neg = 0
    n_test_data = len(test_features)
    t1 = perf_counter()
    for i in range(n_test_data): 
        prediction = predict(test_feature_array[i])
        if prediction == test_label_array[i]:
            if prediction == 1:
                true_pos += 1
            else:
                true_neg += 1
        else:
            if prediction == 1:
                false_pos += 1
            else:
                false_neg += 1
    t2 = perf_counter()
    time_te = t2 - t1
    acc_te = 100 * (true_pos + true_neg) / n_test_data
    print("When N =", N)
    print("Training Accuracy: {:.2f}%".format(acc_tr))
    print("Training Time: {:.2f}s".format(time_tr))
    print("Test Accuracy: {:.2f}%".format(acc_te))
    print("Test Time: {:.2f}s".format(time_te))
    print("...")

np.errstate(all = 'ignore')
for i in [600, 500, 400, 300, 200, 100]:
    N = i
    MI = MI[:N]
    write_all()

np.array([[true_pos, false_pos],
[false_neg, true_neg]])







np.array([[true_pos, false_pos],
[false_neg, true_neg]])





